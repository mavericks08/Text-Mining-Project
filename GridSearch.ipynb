{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from statistics import mean \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1034,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.read_excel('processedfeaturesDF.xlsx')\n",
    "\n",
    "class_labels=[]\n",
    "class_labels=(testdf['class_labels'])\n",
    "\n",
    "# best pre-processed was with normalization, wordlist and stopwords, i.e. processedfeatures3\n",
    "processed_features3=[]\n",
    "processed_features3=(testdf['processed_features3'])\n",
    "\n",
    "processed_features3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running GridSearch to get best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 192 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed: 18.6min finished\n",
      "C:\\Users\\melvi\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are :\n",
      "clf__C\t 1\n",
      "clf__kernel\t 'linear'\n",
      "vect__binary\t False\n",
      "vect__max_df\t 0.4\n",
      "vect__max_features\t 5000\n",
      "vect__min_df\t 6\n",
      "Accuracy score: 0.8108108108108109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(processed_features3,class_labels)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', min_df=5, max_df=0.8, sublinear_tf=True)),\n",
    "    ('clf', svm.SVC(gamma='scale')),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_features': (2500, 5000),\n",
    "    'vect__binary': (True, False),\n",
    "    'vect__min_df': (5,6),\n",
    "    'vect__max_df': (0.1, 0.4),\n",
    "    'clf__C': (0.1, 1, 0.5, 10),\n",
    "    'clf__kernel': ('rbf','linear','poly'),    \n",
    "}\n",
    "    \n",
    "gridsearch = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=10)\n",
    "gridsearch.fit(train_x, train_y)\n",
    "# print(\"Best score is : %f \"% gridsearch.best_score_)\n",
    "print(\"Best Parameters are :\")\n",
    "best_parameters = gridsearch.best_estimator_.get_params()\n",
    "for parametername in sorted(parameters.keys()):\n",
    "    print(\"%s\\t %r\"% (parametername, best_parameters[parametername]))\n",
    "prediction = gridsearch.predict(valid_x)\n",
    "print(\"Accuracy score:\", accuracy_score(valid_y, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
